{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129402aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# week 9: poisson processes, discrete traits, and CTMCs\n",
    "\n",
    "## eeb463\n",
    "\n",
    "## tomo parins-fukuchi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d4fa7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## thomas bayes\n",
    "\n",
    "- okay we are going to revisit some things\n",
    "\n",
    "![bg right h:700](images/tbayes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a42f33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- the likelihood is the probability of the data given a model, $P(D|M)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b68e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- imagine you are in your apartment and hear a huge crash above you\n",
    "- what is the probability of hearing this crash if: \n",
    "    - $M_{0}$: minions are bowling in the apartment upstairs?\n",
    "    - $M_{1}$: the neighbor who just moved in dropped a large box of stuff that scattered?\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57608d02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- $L(M_{0}) \\approx 1$ <- you would almost certainly hear noises if minions were bowling upstairs\n",
    "- $L(M_{1}) \\approx 1$ <- this scenario would also almost certainly yield a banging sound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed697f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- **conclusion:** the likelihood is profoundly useful but carries limitations when used to draw inference\n",
    "- _we want a way to assess $P(M|D)$_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d22f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayes' theorem\n",
    "\n",
    "$$ P(M | D) = \\frac{P(M) P(D | M)}{P(D)} $$\n",
    "\n",
    "- $P(M | D)$ is called the **posterior** probability\n",
    "- $P(M)$ is the **prior** probability\n",
    "    - what was the probability of the model before we collected any observations?\n",
    "- $P(D | M)$ is the likelihood\n",
    "- $P(D)$ is the probability of the data across the entire universe of possible models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9383c644",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- under maximum likelihood, we aimed to find the minimum along a negative log likelihood surface\n",
    "- we call this the maximum likelihood estimate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138d3af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import distributions as dist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "norm = dist.normal(1.0,1.0)\n",
    "\n",
    "surf = [-norm.log_pdf(i) for i in np.linspace(0.,2.,30)]\n",
    "\n",
    "plt.plot(np.linspace(0.,2.,30),surf)\n",
    "plt.ylabel(\"negative log-likleihood\")\n",
    "plt.xlabel(\"mean estimate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05263cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- for bayesian inference, we want the estimate with the highest **posterior probability** (i.e., $P(M|D)$)\n",
    "- one problem with this is that $P(D)$ is very difficult to deal with\n",
    "\n",
    "\n",
    "$$ P(M | D) = \\frac{P(M) P(D | M)}{P(D)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad346899",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- bayesian inference can target several types of estimates\n",
    "    - **maximum _a posteriori_ (MAP)**: what parameter value has the highest posterior prob?\n",
    "        - which values of &mu; and &sigma; maximize $P(M|D)$?\n",
    "        - this is a point estimate, similar to MLE\n",
    "    - **posterior distribution**: also common to estimate the entire posterior probability _distribution_\n",
    "        - $P(M|D)$, $P(M)$, $P(D|M)$ reflect distributions over a range of param. values\n",
    "        - for anole svl, we want the _distribution_ of $P(M|D)$ over different values of &mu; and &sigma;\n",
    "        - usually involves calculating or approximating a very complicated integral\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543807da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- with maximum likelihood, we searched for the peak on the likelihood surface by plugging and chugging\n",
    "- here, we will seek a way to approximate the **posterior probability distribution** using random sampling\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9213d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## markov chain monte carlo (MCMC)\n",
    "\n",
    "- construct a random walk (i.e., a \"markov chain\") that converges on the posterior distribution\n",
    "- simulates draws from the posterior distribution to approximate the integral\n",
    "  - run many iterations, each time simulate a single sample from the posterior\n",
    "  - we can make these draws given a function that is proportional to the posterior probability\n",
    "\n",
    "$$ P(M | D) = \\frac{P(M) P(D | M)}{P(D)} \\propto P(M) P(D | M) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b064a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## metropolis-hastings algorithm\n",
    "\n",
    "- discovered in 1953 by a group of former manhattan project scientists\n",
    "- can draw samples from a target distribution if given a function _proportional to_ the density of the target\n",
    "\n",
    "$$ P(M | D) = \\frac{P(M) P(D | M)}{P(D)} \\propto P(M) P(D | M) $$\n",
    "\n",
    "- since numerator is proportional to the posterior, we can use it for MH simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972520e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## metropolis-hastings algorithm (the recipe)\n",
    "\n",
    "1. initialize parameter vector, $x$ (could simply be random) and start the chain (for loop)\n",
    "2. update parameters to create new vector $x'$\n",
    "    - these proposals are drawn from proposal distributions of the user's choice\n",
    "3. compute the ratio $R = \\frac{P(x')P(D|x')}{P(x)P(D|x)}$\n",
    "4. accept $x'$ with probability $R$ \n",
    "    - always accept if new params better than old (i.e., $P(x')P(D|x') > P(x)P(D|x)$)\n",
    "    - we accept _worse_ param values with some probability\n",
    "5. return to 2 and repeat many times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251cbc8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## metropolis-hastings algorithm\n",
    "\n",
    "- each repetition of steps 2-4 yields a single draw from the posterior distribution\n",
    "- let's go back through our example to illustrate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643c840",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- let's bring back our simulated anoles for an example:\n",
    "    - model SVL measurements for a population of lizards using a normal distribution\n",
    "    - **what is the posterior distribution of values the mean and sd can take?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb57aa8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def norm_ll(mean, sd, x):\n",
    "    dens = math.log((1.0/(sd*math.sqrt(2.*math.pi))))+((-.5 * (((x - mean)/sd)**2.)))\n",
    "    return dens\n",
    "\n",
    "def svl_norm_ll(mean,sd, data):\n",
    "    return sum([norm_ll(mean,sd, i) for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef279601",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import random, math\n",
    "\n",
    "svl = dist.normal(130.0,10.0).sample(50)\n",
    "mean = 115.\n",
    "sd = 10.\n",
    "mean_prop = dist.normal(0., 4.)\n",
    "ll = svl_norm_ll(mean,sd,svl)\n",
    "\n",
    "\n",
    "gen = 100000\n",
    "thin = 100\n",
    "gens = []\n",
    "samples = []\n",
    "mean_samp = []\n",
    "accept = 0\n",
    "for i in range(gen):\n",
    "    mean_star = mean + mean_prop.sample(1)[0]\n",
    "        \n",
    "    ll_star = svl_norm_ll(mean_star,sd,svl)\n",
    "    \n",
    "    ratio = math.exp(ll_star - ll)\n",
    "    if ratio >= 1. or random.random() < ratio:\n",
    "        accept+=1\n",
    "        ll = ll_star\n",
    "        mean = mean_star\n",
    "\n",
    "    if i % thin == 0:\n",
    "\n",
    "        gens.append(i)\n",
    "        samples.append(ll)\n",
    "        mean_samp.append(mean)\n",
    "        \n",
    "\n",
    "print(\"proportion of proposals accepted:\",accept/gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0c70f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "postburn = gen // 10 // 100  # get rid of all of the \"burn-in\" samples\n",
    "postburn_mu = mean_samp[postburn:]\n",
    "plt.plot(gens[postburn:],postburn_mu)\n",
    "plt.xlabel(\"generation\")\n",
    "plt.ylabel(\"mean estimate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b31b589",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- parameter values with higher posterior probability will be visited more often in the chain\n",
    "\n",
    "- we can plot a histogram of all our simulated draws\n",
    "  - this is an approximation of the posterior distribution of $\\mu$\n",
    "\n",
    "- resulting distribution can give us a single \"best\" estimate of $\\mu$ but also our confidence in that estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f79738",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(postburn_mu)\n",
    "plt.ylabel(\"count\")\n",
    "plt.xlabel(\"mean estimate\")\n",
    "lower = np.quantile(postburn_mu,0.025)\n",
    "upper = np.quantile(postburn_mu,0.975)\n",
    "plt.axvline(dist.mean(postburn_mu),color=\"black\")\n",
    "plt.axvline(lower,color=\"grey\")\n",
    "plt.axvline(upper,color=\"grey\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b241814",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## bayesian inference\n",
    "\n",
    "- let's go back over our OU example from last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9aa311",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## simulate our data\n",
    "\n",
    "theta = 90.0\n",
    "sigma = 1.0\n",
    "\n",
    "dt = 0.1\n",
    "total_myr = 10.0\n",
    "n_iter = int(total_myr / dt)\n",
    "\n",
    "\n",
    "norm = dist.normal(mean=0.0, sd = 1.0)\n",
    "curtime = 0.0\n",
    "times = []\n",
    "y_t = 100.0\n",
    "pheno = []\n",
    "\n",
    "for i in range(n_iter-1):\n",
    "    pheno.append(y_t)\n",
    "    times.append(curtime)\n",
    "    delta_y = (  ( theta - y_t )  * dt) + (norm.sample(1)[0] * sigma * math.sqrt(dt))\n",
    "    y_t += delta_y\n",
    "    curtime = curtime + 0.1\n",
    "        \n",
    "plt.plot(times,pheno)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38099d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### our 2-parameter likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7b630",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def stasis_ts_ll(theta, sigma, times, data):\n",
    "    ll = 0.0\n",
    "    for i in range(1,len(times)):\n",
    "        cur_val = data[i]\n",
    "        last_val = data[i-1]\n",
    "        delta_y = cur_val - last_val\n",
    "        delta_t = times[i] - times[i-1]\n",
    "        mean = (  theta - last_val ) * delta_t \n",
    "        sd = sigma * math.sqrt(delta_t)\n",
    "        stepll = math.log((1.0 / (sd*math.sqrt(2.*math.pi)))) + ((-.5 * (((delta_y - mean) / sd) ** 2.)))\n",
    "        ll += stepll\n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3230ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### write a function to generate >0 proposals for $\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416b295",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## define function to propose new values for sigma\n",
    "\n",
    "def generate_sigma_proposal(sigma, prop_dist):\n",
    "    while True:\n",
    "        sigma_star = sigma + prop_dist.sample(1)[0]\n",
    "        if sigma_star > 0.:  # make sure we aren't proposing negative values for sigma\n",
    "            break\n",
    "    return sigma_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3dd109",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MCMC on a 2-parameter model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f221fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def stasis_MCMC(gen,thin,start_p,theta_prior,sigma_prior,theta_prop,sigma_prop):\n",
    "    theta = start_p[0]\n",
    "    sigma = start_p[1]\n",
    "    ll = stasis_ts_ll(theta,sigma,times,pheno) + theta_prior.log_pdf(theta) + sigma_prior.log_pdf(sigma)\n",
    "    \n",
    "    theta_samp = [theta]\n",
    "    sigma_samp = [sigma]\n",
    "    gens = [0]\n",
    "    accept = 0\n",
    "\n",
    "    for i in range(gen):\n",
    "\n",
    "        if random.random() < .5:                   ## half the time we update theta, the other half sigma\n",
    "            theta_star = theta + theta_prop.sample(1)[0]\n",
    "            sigma_star = sigma\n",
    "        else:\n",
    "            theta_star = theta\n",
    "            sigma_star = generate_sigma_proposal(sigma,sigma_prop)\n",
    "\n",
    "        ll_star = stasis_ts_ll(theta_star,sigma_star,times,pheno) + theta_prior.log_pdf(theta_star) + sigma_prior.log_pdf(sigma_star)\n",
    "        if ll_star - ll > 0.:\n",
    "            ratio = 1.1\n",
    "        else:\n",
    "            ratio = math.exp(ll_star - ll)\n",
    "        if random.random() < ratio:\n",
    "            accept+=1\n",
    "            ll = ll_star\n",
    "            theta = theta_star\n",
    "            sigma = sigma_star\n",
    "\n",
    "        if i % thin == 0:\n",
    "            gens.append(i)\n",
    "            theta_samp.append(theta)\n",
    "            sigma_samp.append(sigma)\n",
    "    \n",
    "    print(\"MCMC complete. Acceptance ratio:\",accept / gen)\n",
    "    return gens,theta_samp,sigma_samp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3963020b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MCMC on a 2-parameter model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56356802",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import random, math\n",
    "\n",
    "\n",
    "theta, sigma = 80., 1.3\n",
    "theta_prior = dist.normal(80., 5.)\n",
    "sigma_prior = dist.normal(2.3, 0.25)\n",
    "theta_prop = dist.normal(0.0, 0.8)\n",
    "sigma_prop = dist.normal(0., 0.23)\n",
    "\n",
    "gen = 100000\n",
    "thin = 100\n",
    "\n",
    "gens, theta_samp, sigma_samp = stasis_MCMC(gen,thin,[theta,sigma],theta_prior,sigma_prior,theta_prop,sigma_prop)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206643c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## markov chain for &theta; and &sigma;\n",
    "\n",
    "- let's discard the first 10% of samples as burn-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39c3cc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "burnin = gen // 100 // 10 \n",
    "theta_pb = theta_samp[burnin:] # remove first 10% of samples\n",
    "sigma_pb = sigma_samp[burnin:]\n",
    "gens_pb = gens[burnin:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6817030",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## markov chain for &theta; and &sigma;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140c319",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "ax1.plot(gens_pb, theta_pb)\n",
    "ax1.xaxis.set_tick_params(labelbottom=False)\n",
    "ax1.set(xlabel=\"\", ylabel=\"theta value\")\n",
    "ax2.plot(gens_pb, sigma_pb)\n",
    "ax2.set(xlabel=\"generation\", ylabel=\"sigma value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb43fdf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## estimated posterior distribution of theta and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a6bd1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.hist(theta_pb)\n",
    "ax1.set(xlabel=\"theta\", ylabel=\"\")\n",
    "ax2.hist(sigma_pb)\n",
    "ax2.set(xlabel=\"sigma\", ylabel=\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21de12f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### compare the posterior to the prior for $\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ac053",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prior_samp = [sigma_prior.sample(1)[0] for _ in range(len(sigma_samp))]\n",
    "\n",
    "weights = np.ones_like(prior_samp) / len(prior_samp)\n",
    "plt.hist(prior_samp,alpha=0.5,label=\"prior\",weights=weights)\n",
    "plt.hist(sigma_samp,alpha=0.5,label=\"posterior\",weights=weights)\n",
    "plt.xlabel(\"sigma\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86d232",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "break!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcc15c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## poisson processes\n",
    "\n",
    "- now we will explore a new class of stochastic models\n",
    "- these will concern themselves with modelling the stochastic timing of discrete events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78f3e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **how often do things happen?**\n",
    "\n",
    "- amino acid substitutions along a protein\n",
    "- speciation events in a large clade\n",
    "- fossil deposition events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8c9b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **how often do things happen?**\n",
    "\n",
    "- might imagine a stochastic **rate**:\n",
    "    - substitution rate\n",
    "    - speciation rate\n",
    "    - fossilization rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba494a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **how often do things happen?**\n",
    "\n",
    "- might imagine a stochastic **rate**:\n",
    "    - substitution rate: how many substitutions occur per million years?\n",
    "    - speciation rate: how many new species form per million years?\n",
    "    - fossilization rate: how many fossils are preserved per million years?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d006bac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## protein evolution\n",
    "\n",
    "- one common use of a poisson process is to model stochastic changes in a protein sequence\n",
    "- imagine amino acid substitutions occur randomly at some rate\n",
    "- simulating the timing of changes should be straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a8f76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# how many substitutions occur in a protein after 1000 time steps?\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_subs = 0\n",
    "stt = [n_subs]\n",
    "rate = 0.05\n",
    "for i in range(999):\n",
    "    r = random.random()\n",
    "    if r < rate:\n",
    "        n_subs += 1\n",
    "    stt.append(n_subs)\n",
    "\n",
    "plt.plot([i for i in range(1000)], stt,\"o\")\n",
    "plt.xlabel(\"time step\")\n",
    "plt.ylabel(\"# substitutions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d48318e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **how many events can we expect in time window $\\Delta t$?**\n",
    "\n",
    "- Simulation under this model is straightforward but there are mathematical expressions that are also useful\n",
    "- In particular, a situation like this is often modelled using the **Poisson** distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e0a96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "subs = []\n",
    "for _ in range(500):\n",
    "    n_subs = 0\n",
    "    rate = 0.05\n",
    "    for i in range(999):\n",
    "        r = random.random()\n",
    "        if r < rate:\n",
    "            n_subs += 1\n",
    "    subs.append(n_subs)\n",
    "\n",
    "plt.hist(subs)\n",
    "plt.xlabel(\"# substitutions\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80444e53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Poisson distribution**\n",
    "\n",
    "- Discrete probability distribution\n",
    "- 1 parameter:\n",
    "  - &lambda; -- how often do events happen?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e81b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Poisson PMF**\n",
    "\n",
    "- Probability of _k_ events in an interval, $t$:\n",
    "\n",
    "$$\\frac{(\\lambda t)^ke^{-\\lambda t}}{k!}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029562fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    nums = [i for i in range(n,1,-1)]\n",
    "    prod = 1\n",
    "    for i in nums:\n",
    "        prod *= i\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368619c7",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def poisson_pmf(lam, t, k):\n",
    "    num = ((lam*t)**k) * math.exp(-(lam*t))\n",
    "    denom = factorial(k)\n",
    "    return num / denom\n",
    "\n",
    "probs = []\n",
    "x = []\n",
    "for i in range(30,70):\n",
    "    probs.append(poisson_pmf(0.05,1000,i))\n",
    "    x.append(i)\n",
    "    \n",
    "plt.plot(x,probs,\"o\")\n",
    "plt.xlabel(\"# substitutions\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fc1da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x,probs,\"o\")\n",
    "\n",
    "plt.hist(subs,alpha=0.5,color=\"grey\",density=True)\n",
    "plt.xlabel(\"# substitutions\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c196c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## **poisson distribution**\n",
    "\n",
    "- Poisson distribution can be derived from the binomial distribution\n",
    "    - Divided into sub-intervals, what is the probability of 'success' (there is an event) vs not (no event) ?\n",
    "    - Limiting case of the binomial where the number of trials approaches infinity\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835a7ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **poisson process**\n",
    "\n",
    "- \\# events (e.g., mutations) over time _t_ follows Poisson distribution\n",
    "- Evolution of mutations over time can be modelled by a **Poisson _process_**\n",
    "    - index a poisson distribution over time\n",
    "- Poisson distribution/process implies additional properties we will explore next week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdcfea6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **poisson process**\n",
    "\n",
    "- For now we will make a departure to explore a specific type of Poisson process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e24a04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- suppose we are studying a species of trilobite and are interested in the evolution of their proboscis \n",
    "\n",
    "![h:500 center](images/discrete0.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d4037",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- imagine that, over time, we tend to see the gain and loss of spines from the end of the proboscis\n",
    "\n",
    "![h:500 center](images/discrete1.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2452f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- many organisms display traits like this that are discontinuous\n",
    "- another example is DNA or protein sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e92a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- point mutations become substitutions and substitutions occur at some rate\n",
    "\n",
    "![h:500 center](images/dna_substitution.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a61eaf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- we can extend the simple poisson process introduced above to incorporate rates of different kinds of events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b9917",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- we will represent each character state using integers:\n",
    "\n",
    "![h:500 center](images/discrete3.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b30d82",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# simulate character history over 10 million years\n",
    "# will arbitrarily set dt to 0.1, so that we will observe (sample) the process every 100kyr\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "char_state = 0\n",
    "states = [char_state]\n",
    "rate = 0.03\n",
    "dt = 0.1\n",
    "curtime = 0.\n",
    "times = [curtime]\n",
    "while curtime < 10.:\n",
    "    curtime += dt\n",
    "    r = random.random()\n",
    "    if r < rate:\n",
    "        char_state = abs(1 - char_state)  # swap current character state to other\n",
    "    states.append(char_state)\n",
    "    times.append(curtime)\n",
    "    \n",
    "\n",
    "plt.plot(times,states)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa74ef2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- here we have simulated changes between 0 and 1 according to a Poisson process\n",
    "- what if there is asymmetry in different types of changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a9afa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- gains\n",
    "\n",
    "![h:500 center](images/discrete2.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42957e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- losses\n",
    "\n",
    "![h:500 center](images/discrete1.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d6f529",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- this is easy to simulate as a poisson process\n",
    "- we can set up a poisson process with two kinds of events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a9925",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- might have a rate of loss ($r_l$) and a rate of gain ($r_g$)\n",
    "\n",
    "![h:500 center](images/discrete4.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9117035",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- we can build a matrix of rates emcompassing each kind of of event\n",
    "\n",
    "![h:500 center](images/rate_mat.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5038ee4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- we typically call this the _Q_ matrix\n",
    "- formulate it so that the rows sum to 0\n",
    "\n",
    "![h:500 center](images/rate_mat1.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ea73c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- this matrix gives the instantaneous rate of all types of changes\n",
    "- this type of model is called a **continuous-time Markov chain (CTMC)**\n",
    "- we can also use it to compute the probabilities of different types of changes given _dt_\n",
    "    - we call this the _P_ matrix\n",
    "    \n",
    "$$ P = e^{Qdt}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a42fa75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import expm\n",
    "\n",
    "gain = 0.2\n",
    "loss = 0.1\n",
    "dt = 0.1\n",
    "\n",
    "Q = np.array(\n",
    "    [ \n",
    "    [-gain,gain], \n",
    "    [loss,-loss] \n",
    "    ])\n",
    "\n",
    "P = expm(Q*dt)\n",
    "\n",
    "print(P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f7ea1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- we could now modify our simulation code to accomodate this matrix of rates rather than just a single poisson rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae9dc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# simulate character history over 10 million years\n",
    "# will arbitrarily set dt to 0.1, so that we will observe (sample) the process every 100kyr\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sim_discrete(Q, time_window, dt = 0.1):\n",
    "    char_state = 0\n",
    "    states = [char_state]\n",
    "    curtime = 0.\n",
    "    times = [curtime]\n",
    "    while curtime < time_window:\n",
    "        curtime += dt\n",
    "        P = expm(Q*dt)\n",
    "        cur_row = P[char_state]  # we'll pull out the row corresponding to our current state\n",
    "        prob_change = cur_row[abs(1 - char_state)]  # find probability of change by pulling index opposite of char_state\n",
    "        r = random.random()\n",
    "        if r < prob_change:\n",
    "            char_state = abs(1 - char_state)  # swap current character state to other\n",
    "        states.append(char_state)\n",
    "        times.append(curtime)\n",
    "    return times, states\n",
    "\n",
    "times,states = sim_discrete(Q, 10.)\n",
    "plt.plot(times,states)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad848e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## a note on time  and _dt_\n",
    "\n",
    "- like Brownian motion, this is a continuous time model\n",
    "- we just _sample_ the process at different points\n",
    "- so _dt_ can be arbitrary\n",
    "    - _P_ is a function of both _Q_ and _dt_\n",
    "    - how does it change as _dt_ increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d50cd4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def set_Q(gain,loss):\n",
    "    Q = np.array(\n",
    "        [ \n",
    "        [-gain, gain], \n",
    "        [loss, -loss] \n",
    "        ])\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e272748",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import expm\n",
    "\n",
    "dt = 0.9\n",
    "gain = 0.2\n",
    "loss = 0.05\n",
    "\n",
    "Q = set_Q(gain,loss)\n",
    "\n",
    "P = expm(Q*dt)\n",
    "\n",
    "print(P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8844bee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- one more property of CTMCs to discuss\n",
    "- the **stationary distribution**:\n",
    "  - what are the probabilities of each state when time in the chain $\\rightarrow \\infty$ ?\n",
    "  - you will derive this in the homework, but first, we'll simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1b9d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gain = 0.2\n",
    "loss = 0.05\n",
    "\n",
    "Q = set_Q(gain,loss)\n",
    "\n",
    "all_states = []\n",
    "\n",
    "for _ in range(10):\n",
    "    times, states = sim_discrete(Q, 100.)\n",
    "    times = times[100:]\n",
    "    states = states[100:]\n",
    "    all_states += states\n",
    "    plt.plot(times,states,color='grey',alpha=0.2)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965d4f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p0 = np.array(all_states.count(0)) / float(len(all_states))\n",
    "p1 = np.array(all_states.count(1)) / float(len(all_states))\n",
    "\n",
    "fig, ax  = plt.subplots()\n",
    "ax.bar([1, 2], [p0, p1], width=1,\n",
    "       tick_label=['state 0', 'state 1'], align='center')\n",
    "plt.ylabel(\"probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0b7dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- given the stationary distribution, the probability of each state is proportional to the rates\n",
    "- we will explore more in the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5ffdb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(p1 / p0)\n",
    "print(gain / loss) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0d326",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- we can also perform statistical inference under this model\n",
    "- each cell in _P_ gives probability of going from one state to another\n",
    "    - e.g., $P(0\\rightarrow1 | Q)$ \n",
    "    - each of these probabilities can be used as a likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2120b15b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "![h:500 center](images/ctmc.svg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3bec8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# write a function to calculate the log-likelihood of a particular time series under the CTMC\n",
    "\n",
    "def calc_disc_loglike(times, data, gain, loss):\n",
    "    ll = 0.0\n",
    "    for i in range(1,len(times)):\n",
    "        cur_state = data[i]\n",
    "        last_state = data[i-1]\n",
    "        dt = times[i] - times[i-1]\n",
    "        Q = set_Q(gain,loss)\n",
    "        P = expm(Q*dt)\n",
    "        like = P[last_state][cur_state]\n",
    "        stepll = math.log(like)\n",
    "        ll += stepll\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf4e42",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# visualize log-likelihood surface over values of gain rate parameter\n",
    "\n",
    "test_gains = np.linspace(0.1,0.4,20)\n",
    "\n",
    "likes = [calc_disc_loglike(times,states,i,loss) for i in test_gains]\n",
    "plt.plot(test_gains,likes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba8f57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# visualize 2d likelihood surface for both rates\n",
    "\n",
    "times,states = sim_discrete(Q, 10.)\n",
    "\n",
    "X = np.linspace(.01, .4, 40)\n",
    "Y = np.linspace(.01, .4, 40)\n",
    "Xgrid, Ygrid = np.meshgrid(X, Y)\n",
    "z = []\n",
    "\n",
    "for yi in Y: \n",
    "    y_ll = []\n",
    "    for xi in X:\n",
    "        ll = calc_disc_loglike(times,states,xi,yi)\n",
    "        y_ll.append(ll)\n",
    "        \n",
    "    z.append(y_ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aead6cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# visualize 2d likelihood surface for both rates\n",
    "\n",
    "\n",
    "levels = np.linspace(min(min(z)),max(max(z)),15) \n",
    "fig, ax = plt.subplots()\n",
    "CS = ax.contour(Xgrid,Ygrid,z,levels=levels)\n",
    "ax.clabel(CS, inline=True, fontsize=10)\n",
    "plt.xlabel(\"gain rate\")\n",
    "plt.ylabel(\"loss rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47b6a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "\n",
    "- statistical estimation of rate parameters is tricky due to low information\n",
    "- high stochastic variability across simulated datasets b/c small sample size\n",
    "- we could increase statistical power by:\n",
    "    - sampling for a longer timespan\n",
    "    - adding more lineages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb33e5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- this approach is still very useful. this model is frequently used in biology to:\n",
    "    - infer phylogenetic trees using DNA, protein, and morphological data\n",
    "    - reconstruct rates of change in a trait (using datasets larger than simulated here)\n",
    "- model spread of infectious disease through population "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c200e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discrete trait evolution\n",
    "\n",
    "- these models are used for all kinds of things, even outside of biology\n",
    "\n",
    "![h:500 center](images/financial_markov.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fcede9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd526f4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "everything below is discard stuff that i wanted to keep around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ce5ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def gen_positive_prop(val, prop_dist): \n",
    "    positive = False\n",
    "    while True:\n",
    "        val_star = val + prop_dist.sample(1)[0]\n",
    "        if val_star > 0.:\n",
    "            return val_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15cbca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def discrete_MCMC(times, states, gen,thin,start_p,gain_prior,loss_prior,gain_prop,loss_prop):\n",
    "    gain = start_p[0]\n",
    "    loss = start_p[1]\n",
    "    ll = calc_disc_loglike(times,states,gain,loss) + gain_prior.log_pdf(gain) + loss_prior.log_pdf(loss)\n",
    "    \n",
    "    gain_samp = [gain]\n",
    "    loss_samp = [loss]\n",
    "    gens = [0]\n",
    "    accept = 0\n",
    "\n",
    "    for i in range(gen):\n",
    "        if random.random() < .5:                   ## half the time we update gain, the other half loss\n",
    "            gain_star = gen_positive_prop(gain,gain_prop)\n",
    "            loss_star = loss\n",
    "        else:\n",
    "            gain_star = gain\n",
    "            loss_star = gen_positive_prop(loss,loss_prop)\n",
    "            \n",
    "        ll_star = calc_disc_loglike(times,states,gain_star,loss_star) + gain_prior.log_pdf(gain_star) + loss_prior.log_pdf(loss_star)\n",
    "        if ll_star - ll > 0.:\n",
    "            ratio = 1.1\n",
    "        else:\n",
    "            ratio = math.exp(ll_star - ll)\n",
    "        if random.random() < ratio:\n",
    "            accept+=1\n",
    "            ll = ll_star\n",
    "            gain = gain_star\n",
    "            loss = loss_star\n",
    "\n",
    "        if i % thin == 0:\n",
    "            print(i)\n",
    "            gens.append(i)\n",
    "            gain_samp.append(gain)\n",
    "            loss_samp.append(loss)\n",
    "    \n",
    "    print(\"MCMC complete. Acceptance ratio:\",accept / gen)\n",
    "    return gens,gain_samp,loss_samp\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf00a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gain, loss = 0.1 , 0.1\n",
    "gain_prior = dist.normal(0.3, 0.1)\n",
    "loss_prior = dist.normal(0.3, 0.1)\n",
    "gain_prop = dist.normal(0.0, 0.05)\n",
    "loss_prop = dist.normal(0.0, 0.05)\n",
    "\n",
    "gen = 1000\n",
    "thin = 10\n",
    "\n",
    "gens, theta_samp, sigma_samp = discrete_MCMC(times, states, gen,thin,[gain,loss],gain_prior,loss_prior,gain_prop,loss_prop)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914abf3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "burnin = gen // 100 // 10 \n",
    "theta_pb = theta_samp[burnin:] # remove first 10% of samples\n",
    "sigma_pb = sigma_samp[burnin:]\n",
    "gens_pb = gens[burnin:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa3c09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## markov chain for gain and loss rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292ac29",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "ax1.plot(gens_pb, theta_pb)\n",
    "ax1.xaxis.set_tick_params(labelbottom=False)\n",
    "ax1.set(xlabel=\"\", ylabel=\"theta value\")\n",
    "ax2.plot(gens_pb, sigma_pb)\n",
    "ax2.set(xlabel=\"generation\", ylabel=\"sigma value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946ca4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## estimated posterior distribution of rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9c6d3",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.hist(theta_pb)\n",
    "ax1.set(xlabel=\"theta\", ylabel=\"\")\n",
    "ax2.hist(sigma_pb)\n",
    "ax2.set(xlabel=\"sigma\", ylabel=\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0309ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "prior_samp = [sigma_prior.sample(1)[0] for _ in range(len(sigma_samp))]\n",
    "\n",
    "weights = np.ones_like(prior_samp) / len(prior_samp)\n",
    "plt.hist(prior_samp,alpha=0.5,label=\"prior\",weights=weights)\n",
    "plt.hist(sigma_samp,alpha=0.5,label=\"posterior\",weights=weights)\n",
    "plt.xlabel(\"sigma\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05c55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57390cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
